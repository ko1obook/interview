version: '3'

services:
  zookeeper:  # Координация Kafka broker
      image: confluentinc/cp-zookeeper:7.4.0
      hostname: zookeeper  # Имя для обращения внутри сети
      container_name: zookeeper
      ports:
        - "2181:2181"  # Зарезервированный порт Zookeeper
      environment:
        ZOOKEEPER_CLIENT_PORT: 2181  # Порт для подключения
        ZOOKEEPER_TICK_TIME: 2000  # Время ожидания
      healthcheck:
        test: ['CMD', 'bash', '-c', "echo 'ruok' | nc localhost 2181"]  # Проверка доступности порта
        interval: 10s
        timeout: 5s
        retries: 5
      networks:
        - confluent  # Изолированная сеть для связи контейнеров

  broker:  # 
    image: confluentinc/cp-server:7.4.0
    hostname: broker  # Имя для обращения внутри сети
    container_name: broker
    depends_on:  # Запускать после healthcheck Zookeeper
      zookeeper:
        condition: service_healthy
    ports:  # Порты для подключения
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'  # Ссылка на Zookeeper
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT  # Подключение без шифрования
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter  # Отчеты о работе
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1  # Репликация данных
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1  # Репликация данных
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1  # Репликация данных
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1  # Репликация данных
      KAFKA_JMX_PORT: 9101  # Порт для мониторинга
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081  # Управление схемами сообщейний
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker:29092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1  # Репликация данных
      CONFLUENT_METRICS_ENABLE: 'false'  # Отключение метрик
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'  # Бесплатновое использование
    networks:
      - confluent  # Изолированная сеть для связи контейнеров
    healthcheck:  # Проверка доступности порта
      test: [ "CMD", "bash", "-c", 'nc -z localhost 9092' ]
      interval: 10s
      timeout: 5s
      retries: 5

  schema-registry:  # Валидация данных. Управление версиями схем. Поддержание совместимости
    image: confluentinc/cp-schema-registry:7.4.0
    hostname: schema-registry  # Имя для обращения внутри сети
    container_name: schema-registry  # Имя контейнера для отладки
    depends_on:  # Запускать после healthcheck брокера
      broker:
        condition: service_healthy
    ports:  # Зарезервированные порты для подключения
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry  # Имя хоста в Kafka-кластере
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:29092'  # Взаимодействие с kafka брокером
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    networks:  # Изолированная сеть для связи контейнеров
      - confluent
    healthcheck:  # Проверка доступности порта
      test: [ "CMD", "curl", "-f", "http://localhost:8081/" ]
      interval: 30s
      timeout: 10s
      retries: 5
  
  # control-center: Мониторинг производительности, настройка топиков, 
  #                 анализ потоков данных и управление Kafka-кластером
  control-center:  
    image: confluentinc/cp-enterprise-control-center:7.4.0
    hostname: control-center  # Имя для обращения внутри сети
    container_name: control-center  # Имя контейнера для отладки
    depends_on:  # Запускать после healthcheck брокера и schema-registry
      broker:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    ports:  # Зарезервированные порты для подключения
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:29092'  # Ссылка на брокер
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"  # Ссылка на schema-registry
      CONTROL_CENTER_REPLICATION_FACTOR: 1  # Репликация данных
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1  # Число партиций для внутренних топиков
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1  # Число партиций для топиков мониторинга
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1  # Репликация данных
      CONFLIENT_METRICS_ENABLE: 'false'  # Отключение метрик
      PORT: 9021  # Порт для подключения
    networks:  # Изолированная сеть для связи контейнеров
      - confluent
    healthcheck:  # Проверка доступности порта
      test: [ "CMD", "curl", "-f", "http://localhost:9021/health" ]
      interval: 30s
      timeout: 10s
      retries: 5


  # webserver: PostgreSQL для хранения данных, загрузка DAG из локальнойпапки, 
  #            Доступ к web-интерфейсу Airflow для пользователей, режим последовательного выполнения задач
  webserver:
    image: apache/airflow:2.6.0-python3.9  # Docker-образ Apache Airflow
    command: webserver  # Запуск веб-сервера airflow webserver
    entrypoint: ['/opt/airflow/script/entrypoint.sh']  # Инициализация базы данных, установку зависимостей
    depends_on:  # Запускать после запуска postgres, !healthcheck не проверяем! для ускорения
      - postgres
    environment:
      - LOAD_EX=n  # Airflow не должен загружать DAG при старте
      - EXECUTOR=Sequential  # Поочерёдное выполнение задач - для тестирования
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow  # Gодключения к БД для хранения метаданных
      - AIRFLOW_WEBSERVER_SECRET_KEY=this_is_a_very_secured_key  # Секретный ключ для обеспечения безопасности веб-сервера Airflow
    logging:  # Логирование с ограничениями
      options:
        max-size: 10m
        max-file: "3"
    volumes:  # Монтаж директории и файлов с хост-машины в контейнер
      - ./dags:/opt/airflow/dags
      - ./script/entrypoint.sh:/opt/airflow/script/entrypoint.sh
      - ./requirements.txt:/opt/airflow/requirements.txt
    ports:
      - "8080:8080"  # Зарезервированный порт для подключения
    healthcheck:  # Проверка доступности порта
      test: ['CMD-SHELL', "[ -f /opt/airflow/airflow-webserver.pid ]"]  # Проверка наличия файла airflow-webserver.pid внутри контейнера
      interval: 30s
      timeout: 30s
      retries: 3
    networks:  # Изолированная сеть для связи контейнеров
      - confluent

  scheduler:  # Управляет выполнением DAG на основе их расписания и зависимостей
    image: apache/airflow:2.6.0-python3.9
    depends_on:  # проверка готовности сервера
      webserver:
        condition: service_healthy
    volumes:  # Монтаж директории и файлов с хост-машины в контейнер
      - ./dags:/opt/airflow/dags
      - ./script/entrypoint.sh:/opt/airflow/script/entrypoint.sh
      - ./requirements.txt:/opt/airflow/requirements.txt
    environment:
      - LOAD_EX=n  # Отключает загрузку примерных DAG при запуске Scheduler, чтобы оставить только пользовательские DAG
      - EXECUTOR=Sequential  # Поочерёдное выполнение задач - для тестирования
      # Подключение к базе данных PostgreSQL, airflow:airflow: 
      # пользователь и пароль, @postgres:5432: хост и порт PostgreSQL
      # /airflow: имя базы данных
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW_WEBSERVER_SECRET_KEY=this_is_a_very_secured_key  # Секретный ключ, который используется для обеспечения безопасности 
    # Установка Python-зависимостей, обновление схемы базы данных Airflow до последней версии
    # Запуск процесса Scheduler, который начинает управлять выполнением задач
    command: bash -c "pip install -r ./requirements.txt && airflow db upgrade && airflow scheduler"
    networks:  # Изолированная сеть для связи контейнеров
      - confluent

  # БД для хранения метаданных DAG, логгировании задач, данные о пользователях, ролях и настройках
  postgres:
    image: postgres:14.0
    environment:  # создание пользователя, для хранения инфы Airflow
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    logging:  # ограничение логирования
      options:
        max-size: 10m
        max-file: "3"
    networks:  # Изолированная сеть для связи контейнеров
      - confluent

  # Менеджер кластера Spark: управление ресурсами. распределение задач между рабочими узлами.
  # Координация выполнения задач в кластере
  spark-master:
    image: bitnami/spark:latest
    command: bin/spark-class org.apache.spark.deploy.master.Master  # Запуск Spark в режиме Master
    ports:  # Веб-интерфейс Spark Master на порт 9090 хоста, 8080 в контейнере
      - "9090:8080"
      - "7077:7077"  # Порт для взаимодействия между Master и Worker 
    networks:  # Изолированная сеть для связи контейнеров
      - confluent

  # Hабочий узел кластера Spark. Выполняет задачи, которые распределяет Master. 
  # В кластере может быть несколько рабочих узлов для обработки больших объёмов данных.
  spark-worker:
    image: bitnami/spark:latest
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077  # Запуск Spark в режиме Worker
    depends_on:  # spark-worker запускается только после того, как spark-master будет запущен. !Без healthcheck!
      - spark-master
    environment:
      SPARK_MODE: worker  # режим работы Spark
      SPARK_WORKER_CORES: 2  # выделение ресурсов
      SPARK_WORKER_MEMORY: 1g  # выделение ресурсов
      SPARK_MASTER_URL: spark://spark-master:7077  # URL для подключения Worker к Master
    networks:  # Изолированная сеть для связи контейнеров
      - confluent

  cassandra_db:  # Поднимаем одноузловую базу данных Cassandra (тест)
    image: cassandra:latest
    container_name: cassandra  # Имя контейнера для отладки и работы через Docker CLI
    hostname: cassandra  # DNS-имя контейнера внутри Docker-сети
    ports:  #  Зарезервированный порт Cassandra из контейнера на хост
      - "9042:9042"
    environment:
      - MAX_HEAP_SIZE=512M  # максимальный размер heap-памяти JVM, используемой Cassandra
      - HEAP_NEWSIZE=100M
      - CASSANDRA_USERNAME=cassandra
      - CASSANDRA_PASSWORD=cassandra
    networks:  # Изолированная сеть для связи контейнеров
      - confluent
networks:
  confluent: